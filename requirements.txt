llama-cpp-python==0.2.20
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0